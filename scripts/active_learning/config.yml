general:
  me: config.yml
  device: cpu
  driver: run.py
  output: [H/ , 0] # Output folder of the model. The model will be saved in root/iter. If it's occupied, iter will be increased by 1 until it's not occupied.
  seed: 10 # random seed

data:
  root: /global/cfs/cdirs/m2963/nmr_Composite/samples/processed_data_jiashu
  # all options: B97-D_pcS-1, B97M-V_pcSseg-1, composite_middle, SCAN_pcSseg-1, wB97X-V_pcSseg-1
  input_lot: wB97X-V_pcSseg-1 # input level of theory
  target_lot: composite_high  # target level of theory
  shift_types: 1 # atomic number of the element you want to predict. 1 for H, 6 for C, 7 for N, 8 for O
  splitting: ../../data_splits/1-7HA_0.txt  # path to splitting file, which tells which molecules are in train, val, test set
             # [0.8, 0.1, 0.1] # if splitting file is not provided, you can specify the ratio of train, val, test set in a list of 3 numbers  

model:
  AEV_outdim: 128 # output dimension of AEV in the first module

training:
  allow_preempt: False # if True, the training will be resumed from the last checkpoint of the same output folder (root/iter/max_subiter), max_subiter is the maximum subiter of resumed trainings
  epochs: 750 # total number of epochs
  batch_size: 128 
  lr: 1.0e-3 # initial learning rate
  # plateau : when validation error does not decrease in 20 epochs, decrease learning rate to 70%,
  # unless learning rate is smaller than 1e-6
  lr_scheduler: [plateau, 20, 20, 0.4, 1.0e-6]
  weight_decay: 3.0e-5
  dropout: 0.1
  random_rotation: False # Whether to rotate the molecules by a random angle in each batch. Set true to train data augmentation model

checkpoint:
  log: 1 # print log every 1 epoch
  val: 1 # evaluate validation error every 1 epoch
  ##  model will be saved if the validation error is the lowest
  test: 5 # To save time, the test error is evaluated only if the validation error is the lowest and there has passed 5 epochs since the last test error evaluation
  verbose: False
